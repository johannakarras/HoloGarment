<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@200;400" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="styles.css" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.1/jquery.min.js"></script>

    <meta property="og:site_name" content="Imagen Video: High Definition Video Generation with Diffusion Models" />
    <meta property="og:type" content="video.other" />
    <meta property="og:title" content="Imagen Video" />
    <meta property="og:description" content="High Definition Video Generation with Diffusion Models" />
    <meta property="og:url" content="https://imagen.research.google/video" />
    <meta property="og:image" content="https://imagen.research.google/video/leaves.png" />

    <meta property="article:publisher" content="https://imagen.research.google/video" />

    <meta name="twitter:card" content="player" />
    <meta name="twitter:title" content="Imagen Video" />
    <meta name="twitter:description" content="High Definition Video Generation with Diffusion Models" />
    <meta name="twitter:url" content="https://imagen.research.google/video" />
    <meta name="twitter:image" content="https://imagen.research.google/video/leaves.png" />
    <meta name="twitter:player" content="https://imagen.research.google/video/videos/leaves.mp4" />
    <meta name="twitter:player:stream" content="https://imagen.research.google/video/videos/leaves.mp4" />
    <meta name="twitter:player:stream:content_type" content="video/mp4" />
    <meta name="twitter:player:width" content="320" />
    <meta name="twitter:player:height" content="192" />

    <title>Imagen Video</title>
  </head>
  <body>
    <div class="video_2" id="video_gallery">
    </div>

    <div class="header" style="background-color: #000000;" id="header_box">
      <div style="position: sticky; top: 0; height: 100vh;" id="header_container">
        <div id="header_video" class="stack" style="display: flex; align-content: center; height: 100vh; overflow-y: hidden;">
          <video id="video" style="opacity: 0.0; width: 100%; object-fit: contain;" autoplay loop muted playsinline><source src="videos/fairytale.mp4" type="video/mp4"></video>
        </div>
        <div class="stack">
          <div class="title" id="title">
            <h1>Imagen Video</h1>
            <h2>imagine &middot; illustrate &middot; inspire</h2>
          </div>
        </div>
      </div>
    </div>

    <div class="section_header">
      <h1>Imagen Video</h1>
      <h2>Google Research, Brain Team</h2>
    </div>

    <div class="abstract">
      <div style="margin: 50px auto;">
        <h1 style="font-weight: 400;">Abstract</h1>
        <p style="padding-bottom: 25px; text-align: justify; font-weight: 300;">We present Imagen Video, a text-conditional video generation system based on a cascade of video diffusion models. Given a text prompt, Imagen Video generates high definition videos using a base video generation model and a sequence of interleaved spatial and temporal video super-resolution models. We describe how we scale up the system as a high definition text-to-video model including design decisions such as the choice of fully-convolutional temporal and spatial super-resolution models at certain resolutions, and the choice of the v-parameterization of diffusion models. In addition, we confirm and transfer findings from previous work on diffusion-based image generation to the video generation setting. Finally, we apply progressive distillation to our video models with classifier-free guidance for fast, high quality sampling. We find Imagen Video not only capable of generating videos of high fidelity, but also having a high degree of controllability and world knowledge, including the ability to generate diverse videos and text animations in various artistic styles and with 3D object understanding.</p>
        <p><a class="read-paper" href="paper.pdf"><button>Research Paper</button></a></p>
      </div>
    </div>

    <div class="section_header">
      <h1>Video Diffusion Models</h1>
      <h2>Cascaded Diffusion Models &times; 3D U-Net</h2>
    </div>

    <div id="zoom_box">
      <div>
        <div style="position: sticky; top: 0; left: 0; height: calc(100vh + 200px); width: 100vw; overflow-x: hidden;">
          <div style="height: calc(100vh + 200px); width: 100vw; position: absolute; top: 0;" id="zoom_in_parent">
            <div style="padding: 100px 0; margin: 0 auto; width: 25%;" id="zoom_in">
              <video autoplay loop muted playsinline><source src="videos/fairytale-2.mp4" type="video/mp4"></video>
              <h1 style="text-align: center; font-size: 2em; display: none; font-weight: 300;">High Definition 1280&times;768 24fps</h1>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="section_header mobileonly">
      <h1>Cascaded Diffusion Models</h1>
      <h2>Spatial Super-Resolution &times; Temporal Super-Resolution</h2>
    </div>

    <div class="abstract mobileonly">
      <img src="cdm-diagram.png" style="width: 100%;" />
      <div style="margin: 50px auto;">
        <p style="text-align: justify; font-weight: 300;">Imagen Video generates high resolution videos with <a href="https://cascaded-diffusion.github.io/">Cascaded Diffusion Models</a>. The first step is to take an input text prompt and encode it into textual embeddings with a <a href="https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html">T5</a> text encoder. A base <a href="https://video-diffusion.github.io/">Video Diffusion Model</a> then generates a 16 frame video at 40&times;24 resolution and 3 frames per second; this is then followed by multiple Temporal Super-Resolution (TSR) and Spatial Super-Resolution (SSR) models to upsample and generate a final 128 frame video at 1280&times;768 resolution and 24 frames per second -- resulting in 5.3s of high definition video!</p>
      </div>
    </div>

    <div id="cdm_box" class="nomobile">
      <div>
        <div style="position: sticky; top: 0; left: 0; height: 100vh; width: 100vw; overflow-x: hidden;">
          <div class="section_header">
            <h1>Cascaded Diffusion Models</h1>
            <h2>Spatial Super-Resolution &times; Temporal Super-Resolution</h2>
          </div>
          <div style="height: 100vh; width: 100vw; position: absolute; top: 0; left: 50vw; display: flex;" id="cdm">
            <div class="cdm_stage">
              <div>
                <div class="top" style="max-width: 300px;"><p style="padding: 25px; font-size: 2em; text-align: center; border: 1px solid #CCCCCC; border-radius: 10px;">Sprouts in the shape of text 'Imagen' coming out of a fairytale book.</p></div>
                <div class="bottom"><p>Text Prompt</p></div>
              </div>
            </div>
            <div class="cdm_stage">
              <div>
                <h1 style="font-size: 8em;">&rightarrow;</h1>
              </div>
            </div>
            <div class="cdm_stage" id="cdm_stage_0">
              <div>
                <div class="top"><video autoplay loop muted playsinline><source src="videos/cdm-1.mp4" type="video/mp4"></video></div>
                <div class="bottom"><p>Base 16&times;40&times;24 3fps</p></div>
              </div>
            </div>
            <div class="cdm_stage">
              <div>
                <h1 style="font-size: 8em;">&rightarrow;</h1>
              </div>
            </div>
            <div class="cdm_stage">
              <div>
                <div class="top"><video autoplay loop muted playsinline><source src="videos/cdm-2.mp4" type="video/mp4"></video></div>
                <div class="bottom"><p>TSR 32&times;40&times;24 6fps</p></div>
              </div>
            </div>
            <div class="cdm_stage">
              <div>
                <h1 style="font-size: 8em;">&rightarrow;</h1>
              </div>
            </div>
            <div class="cdm_stage">
              <div>
                <div class="top"><video autoplay loop muted playsinline><source src="videos/cdm-3.mp4" type="video/mp4"></video></div>
                <div class="bottom"><p>SSR 32&times;80&times;48 6fps</p></div>
              </div>
            </div>
            <div class="cdm_stage">
              <div>
                <h1 style="font-size: 8em;">&rightarrow;</h1>
              </div>
            </div>
            <div class="cdm_stage">
              <div>
                <div class="top"><video autoplay loop muted playsinline><source src="videos/cdm-4.mp4" type="video/mp4"></video></div>
                <div class="bottom"><p>SSR 32&times;320&times;192 6fps</p></div>
              </div>
            </div>
            <div class="cdm_stage">
              <div>
                <h1 style="font-size: 8em;">&rightarrow;</h1>
              </div>
            </div>
            <div class="cdm_stage">
              <div>
                <div class="top"><video autoplay loop muted playsinline><source src="videos/cdm-5.mp4" type="video/mp4"></video></div>
                <div class="bottom"><p>TSR 64&times;320&times;192 12fps</p></div>
              </div>
            </div>
            <div class="cdm_stage">
              <div>
                <h1 style="font-size: 8em;">&rightarrow;</h1>
              </div>
            </div>
            <div class="cdm_stage">
              <div>
                <div class="top"><video autoplay loop muted playsinline><source src="videos/cdm-6.mp4" type="video/mp4"></video></div>
                <div class="bottom"><p>TSR 128&times;320&times;192 24fps</p></div>
              </div>
            </div>
            <div class="cdm_stage">
              <div>
                <h1 style="font-size: 8em;">&rightarrow;</h1>
              </div>
            </div>
            <div class="cdm_stage" id="cdm_stage_last">
              <div>
                <div class="top"><video autoplay loop muted playsinline><source src="videos/fairytale.mp4" type="video/mp4"></video></div>
                <div class="bottom"><p>SSR 128&times;1280&times;768 24fps</p></div>
              </div>
            </div>
          </div>

          <div class="caption" style="height: 150px; width: 100vw; position: absolute; top: calc(100vh - 200px); left: 0; display: flex; align-items: center;" id="cdm">
            <div style="margin: 0 auto; font-size: 1.25em; width: 800px; text-align: justify; font-weight: 300;">Imagen Video generates high resolution videos with <a href="https://cascaded-diffusion.github.io/">Cascaded Diffusion Models</a>. The first step is to take an input text prompt and encode it into textual embeddings with a <a href="https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html">T5</a> text encoder. A base <a href="https://video-diffusion.github.io/">Video Diffusion Model</a> then generates a 16 frame video at 40&times;24 resolution and 3 frames per second; this is then followed by multiple Temporal Super-Resolution (TSR) and Spatial Super-Resolution (SSR) models to upsample and generate a final 128 frame video at 1280&times;768 resolution and 24 frames per second -- resulting in 5.3s of high definition video!</div>
          </div>
        </div>
      </div>
    </div>

    <div class="section_header mobileonly">
      <h1>Video U-Net</h1>
      <h2>Spatial Fidelity &times; Temporal Dynamics</h2>
    </div>

    <div class="abstract mobileonly">
      <img src="video-unet.png" style="width: 100%;" />
      <div style="margin: 50px auto;">
        <p style="text-align: justify; font-weight: 300;">Imagen Video uses the <a href="https://video-diffusion.github.io">Video U-Net</a> architecture to capture spatial fidelity and temporal dynamics. Temporal self-attention (shown in the diagram) is used in the base video diffusion model, while temporal convolutions (not shown in the diagram) are used in the temporal and spatial super-resolution models. The Video U-Net architecture empowers Imagen Video to model long-term temporal dynamics!</p>
      </div>
    </div>

    <div id="unet_box">
      <div style="position: sticky; top: 0; left: 0; height: 100vh; width: 100vw;">
        <div class="section_header">
          <h1><p id="3d" style="display: inline; margin: 0; padding: 0;">Video</p> U-Net</h1>
          <h2>Spatial Fidelity &times; Temporal Dynamics</h2>
        </div>
        <div style="position: absolute; display: flex; width: 100vw; height: 100vh;">
          <div style="margin: 0 auto; overflow-x: clip;">
            <div style="width: 800px; height: 800px; perspective: none; position: relative;" id="unet_canvas">
              <div class="unet_view" id="unet_view_0">
                <div style="position: relative;">
                  <div class="unet_component" style="background-color: #4285F4;">Spatial Convolutions</div>
                  <div class="unet_component arrow" style="transform: translateY(50px);">&darr;</div>
                  <div class="unet_component" style="background-color: #DB4437; transform: translateY(100px);">Spatial Self-Attention</div>
                  <div class="unet_component arrow" style="transform: translateY(150px);">&darr;</div>
                  <div class="unet_component" style="background-color: #0F9D58; transform: translateY(200px); display: none;">Temporal Attention</div>
                </div>
              </div>


              <div class="unet_view" id="unet_view_1">
                <div style="position: relative;">
                  <div class="unet_component" style="background-color: #4285F4;">Spatial Convolutions</div>
                  <div class="unet_component arrow" style="transform: translateY(50px);">&darr;</div>
                  <div class="unet_component" style="background-color: #DB4437; transform: translateY(100px);">Spatial Self-Attention</div>
                  <div class="unet_component arrow" style="transform: translateY(150px);">&darr;</div>
                  <div class="unet_component" style="background-color: #0F9D58; transform: translateY(200px); display: none;">Temporal Attention</div>
                </div>
              </div>

              <div class="unet_view" id="unet_view_2">
                <div style="position: relative;">
                  <div class="unet_component" style="background-color: #4285F4;">Spatial Convolutions</div>
                  <div class="unet_component" style="transform: translateY(50px);">&darr;</div>
                  <div class="unet_component" style="background-color: #DB4437; transform: translateY(100px);">Spatial Self-Attention</div>
                  <div class="unet_component" style="transform: translateY(150px);">&darr;</div>
                  <div class="unet_component" style="background-color: #0F9D58; transform: translateY(200px); display: none;">Temporal Attention</div>
                </div>
              </div>

              <div class="unet_view" id="unet_view_3">
                <div style="position: relative;">
                  <div class="unet_component" style="background-color: #4285F4; display: none;">Spatial Convolutions</div>
                  <div class="unet_component" style="background-color: #DB4437; transform: translateY(100px); display: none;">Spatial Self-Attention</div>
                  <div class="unet_component" style="background-color: #0F9D58; transform: translateY(200px); width: 800px;">Temporal Self-Attention</div>
                </div>
              </div>
            </div>
          </div>
        </div>
      
        <div class="caption" style="height: 150px; width: 100%; position: absolute; top: calc(100vh - 200px); left: 0; margin: 0; padding: 25px 0; display: flex; align-items: center;">
            <div style="margin: 0 auto; font-size: 1.25em; width: 800px; text-align: justify; font-weight: 300;">Imagen Video uses the <a href="https://video-diffusion.github.io">Video U-Net</a> architecture to capture spatial fidelity and temporal dynamics. Temporal self-attention (shown in the diagram) is used in the base video diffusion model, while temporal convolutions (not shown in the diagram) are used in the temporal and spatial super-resolution models. The Video U-Net architecture empowers Imagen Video to model long-term temporal dynamics!</div>
        </div>
      </div>
    </div>

    <div class="section_header">
      <h1>Limitations</h1>
    </div>

    <div class="abstract">
      <div style="margin: 50px auto;">
        <p style="text-align: justify; font-weight: 300;">Generative modeling has made tremendous progress, especially in recent text-to-image models. Imagen Video is another step forward in generative modelling capabilities, advancing text-to-video AI systems. Video generative models can be used to positively impact society, for example by amplifying and augmenting human creativity. However, these generative models may also be misused, for example to generate fake, hateful, explicit or harmful content. We have taken multiple steps to minimize these concerns, for example in internal trials, we apply input text prompt filtering, and output video content filtering. However, there are several important safety and ethical challenges remaining. Imagen Video and its frozen T5-XXL text encoder were trained on problematic data. While our internal testing suggest much of explicit and violent content can be filtered out, there still exists social biases and stereotypes which are challenging to detect and filter. We have decided not to release the Imagen Video model or its source code until these concerns are mitigated.</p>
      </div>
    </div>

    <div class="section_header">
      <h1>Imagen Video</h1>
      <h2>imagine &middot; illustrate &middot; inspire</h2>
    </div>

    <div class="authors">
      <h1 style="font-weight: 400;">Authors</h1>
      <p style="padding-bottom: 25px; font-weight: 200;">Jonathan Ho*, William Chan*, Chitwan Saharia*, Jay Whang*, Ruiqi Gao, Alexey Gritsenko, Diederik P. Kingma, Ben Poole, Mohammad Norouzi, David Fleet, Tim Salimans*</p>
      <p style="padding-bottom: 50px; font-weight: 200;">*Equal Contribution.</p>
      <h1 style="font-weight: 400;">Special Thanks</h1>
      <p style="font-weight: 200;">We give special thanks to Jordi Pont-Tuset and Shai Noy for engineering support. We also give thanks to our artist friends, Alexander Chen, Irina Blok, Ian Muldoon, Daniel Smith, and Pedro Vergani for helping us test Imagen Video and lending us their amazing creativity. We are extremely grateful for the support from Erica Moreira for compute resources. Finally, we give thanks to Elizabeth Adkison, James Bradbury, Nicole Brichtova, Tom Duerig, Douglas Eck, Dumitru Erhan, Zoubin Ghahramani, Kamyar Ghasemipour, Victor Gomes, Blake Hechtman, Jonathan Heek, Yash Katariya, Sarah Laszlo, Sara Mahdavi, Anusha Ramesh, Tom Small, and Tris Warkentin for their support.</p>
    </div>

    <script>

function title(index, element) {
  scrollPos = $(window).scrollTop();
  titleBoxTop = $("#header_box").offset().top;

  titleStartLoc = titleBoxTop;
  titleEndLoc = titleStartLoc + $("#header_box").height() - $(window).height();

  loc = (scrollPos - titleStartLoc) / (titleEndLoc - titleStartLoc);
  loc = Math.max(loc, 0);
  loc = Math.min(loc, 1.0);

  $("#header_container #video").css("opacity", loc);
  $("#header_container #title").css("opacity", 1.0 - loc);
}

function zoom() {
  scrollPos = $(window).scrollTop();
  zoomBoxTop = $("#zoom_box").offset().top;

  zoomInStartLoc = zoomBoxTop - 200;
  zoomInEndLoc = zoomBoxTop + 100;

  slideInStartLoc = zoomInEndLoc + 100;
  slideInEndLoc = slideInStartLoc + 300;

  zoomInLoc = (scrollPos - zoomInStartLoc) / (zoomInEndLoc - zoomInStartLoc);
  zoomInLoc = Math.max(zoomInLoc, 0);
  zoomInLoc = Math.min(zoomInLoc, 1);

  slideInLoc = (scrollPos - slideInStartLoc) / (slideInEndLoc - slideInStartLoc);
  slideInLoc = Math.max(slideInLoc, 0);

  maxPercentage = 65.0;

  if (zoomInLoc <= 0.0) {
    $("#zoom_in").css("width", "25%");
    $("#zoom_in").children("h1").css("display", "none");
  } else {
    $("#zoom_in").css("width", Math.min(25.0 + zoomInLoc * maxPercentage, maxPercentage) + "%");
    if (zoomInLoc >= 0.5) {
      $("#zoom_in").find("h1").css("display", "block");
    } else {
      $("#zoom_in").find("h1").css("display", "none");
    }
  }

  // $("#zoom_in_parent").css("left", slideInLoc * $(window).width());
  // $("#slide_in_parent_0").css("left", -1.0 * $(window).width() + slideInLoc * $(window).width());
  // $("#slide_in_parent_1").css("left", -2.0 * $(window).width() + slideInLoc * $(window).width());
  // $("#slide_in_parent_2").css("left", -3.0 * $(window).width() + slideInLoc * $(window).width());
}

function cdm() {
  scrollPos = $(window).scrollTop();
  cdmBoxTop = $("#cdm_box").offset().top;

  cdmStartLoc = cdmBoxTop;
  cdmEndLoc = cdmStartLoc + $("#cdm_box").height() - $(window).height();

  loc = (scrollPos - cdmStartLoc) / (cdmEndLoc - cdmStartLoc);
  loc = Math.max(loc, 0);
  loc = Math.min(loc, 1.0);

  var s = 0.5 * $(window).width() - $("#cdm_stage_0").outerWidth(true);
  var w = -1.0 * $("#cdm_stage_0").outerWidth(true) - 1.0 * $("#cdm_stage_last").outerWidth(true);
  $("#cdm_box div.cdm_stage").each(function() {
    w += $(this).outerWidth(true);
  });

  $("#cdm").css("left", s - loc * w);
}

function unet() {
  scrollPos = $(window).scrollTop();
  boxTop = $("#unet_box").offset().top;

  startLoc = boxTop;
  endLoc = startLoc + $("#unet_box").height() - $(window).height();

  loc = (scrollPos - startLoc) / (endLoc - startLoc);
  loc = Math.max(loc, 0.0);
  loc = Math.min(loc, 1.0);

  rotationY = "rotateY(-" + loc * 90.0 + "deg)";
  rotationY = "";

  allTranslate = "translateY(-200px) ";

  $("#unet_view_0").css("transform", allTranslate + rotationY);
  $("#unet_view_1").css("transform", allTranslate + "translateX(-" + loc * 300.0 + "px) " + rotationY + "");
  // $("#unet_arrow_1").css("transform", "translateX(-" + loc * 300.0 + "px)");
  $("#unet_view_2").css("transform", allTranslate + "translateX(" + loc * 300.0 + "px) " + rotationY + "");

  $("#unet_view_3").css("transform", allTranslate + "translateX(-" + 300 + "px)");

  // opacity.
  $("#3d").css("opacity", loc);
  // $("div.unet_component").css("height", 1.0 - loc * 0.5);
  $("#unet_view_1").css("opacity", loc);
  $("#unet_view_2").css("opacity", loc);
  $("#unet_view_3").css("opacity", loc);
  // $("#unet_view_3 div.unet_component").css("opacity", 0.5 + loc * 0.5);
}

function drawT5() {
  const canvas = document.getElementById("t5_embs");
  const ctx = canvas.getContext("2d");

  for (var i = 0; i < canvas.width; i += 8) {
    for (var j = 0; j < canvas.height; j += 8) {
      var x = Math.floor(Math.random() * 255.0);
      ctx.fillStyle = `rgb(${x}, ${x}, ${x})`;
      ctx.fillRect(i, j, 8, 8);
    }
  }
}

hdvideos = [
  {"caption": "A beautiful sunrise on mars, Curiosity rover. High definition, timelapse, dramatic colors", "src": "hdvideos/0.mp4"},
  {"caption": "A beautiful sunrise on mars. High definition, timelapse, dramatic colors", "src": "hdvideos/1.mp4"},
  {"caption": "A bicycle on top of a boat.", "src": "hdvideos/2.mp4"},
  {"caption": "A british shorthair jumping over a couch.", "src": "hdvideos/3.mp4"},
  {"caption": "A bunch of autumn leaves falling on a calm lake to form the text 'Imagen Video'. Smooth.", "src": "hdvideos/4.mp4"},
  {"caption": "A bunch of colorful candies falling into a tray in the shape of text 'Imagen Video'. Smooth video.", "src": "hdvideos/5.mp4"},
  {"caption": "A cat eating food out of a bowl, in style of van Gogh.", "src": "hdvideos/6.mp4"},
  {"caption": "A cat on the left of a dog.", "src": "hdvideos/7.mp4"},
  {"caption": "A clear wine glass with turquoise-colored waves inside it.", "src": "hdvideos/8.mp4"},
  {"caption": "A colorful professional animated logo for 'Imagen Video' written using paint brush in cursive. Smooth animation.", "src": "hdvideos/9.mp4"},
  {"caption": "A giraffe underneath a microwave.", "src": "hdvideos/10.mp4"},
  {"caption": "A glass bead falling into water with a huge splash. Sunset in the background.", "src": "hdvideos/11.mp4"},
  {"caption": "A goldendoodle playing in a park by a lake.", "src": "hdvideos/12.mp4"},
  {"caption": "A hand lifts a cup.", "src": "hdvideos/13.mp4"},
  {"caption": "A happy elephant wearing a birthday hat walking under the sea.", "src": "hdvideos/14.mp4"},
  {"caption": "A panda bear driving a car.", "src": "hdvideos/15.mp4"},
  {"caption": "A panda eating bamboo on a rock.", "src": "hdvideos/16.mp4"},
  {"caption": "A panda taking a selfie.", "src": "hdvideos/17.mp4"},
  {"caption": "A shark swimming in clear Carribean ocean.", "src": "hdvideos/18.mp4"},
  {"caption": "A sheep to the right of a wine glass.", "src": "hdvideos/19.mp4"},
  {"caption": "A shiny golden waterfall flowing through glacier at night.", "src": "hdvideos/20.mp4"},
  {"caption": "A shooting star flying through the night sky over mountains.", "src": "hdvideos/21.mp4"},
  {"caption": "A small hand-crafted wooden boat taking off to space.", "src": "hdvideos/22.mp4"},
  {"caption": "A stunning aerial drone footage time lapse of El Capitan in Yosemite National Park at sunset.", "src": "hdvideos/23.mp4"},
  {"caption": "A swarm of bees flying around their hive.", "src": "hdvideos/24.mp4"},
  {"caption": "A teddy bear running in New York City.", "src": "hdvideos/25.mp4"},
  {"caption": "A teddy bear skating in Times Square.", "src": "hdvideos/26.mp4"},
  {"caption": "A teddy bear washing dishes.", "src": "hdvideos/27.mp4"},
  {"caption": "A teddy bear washing the dishes.", "src": "hdvideos/28.mp4"},
  {"caption": "A video of the Earth rotating in space.", "src": "hdvideos/29.mp4"},
  {"caption": "Aerial view of a snow-covered mountain.", "src": "hdvideos/30.mp4"},
  {"caption": "An astronaut riding a horse.", "src": "hdvideos/31.mp4"},
  {"caption": "An umbrella on top of a spoon.", "src": "hdvideos/32.mp4"},
  {"caption": "Balloon full of water exploding in extreme slow motion.", "src": "hdvideos/33.mp4"},
  {"caption": "Bird-eye view of a highway in Los Angeles.", "src": "hdvideos/34.mp4"},
  {"caption": "Campfire at night in a snowy forest with starry sky in the background.", "src": "hdvideos/35.mp4"},
  {"caption": "Coffee pouring into a cup.", "src": "hdvideos/36.mp4"},
  {"caption": "Drone flythrough of a fast food restaurant on a dystopian alien planet", "src": "hdvideos/37.mp4"},
  {"caption": "Drone flythrough of a tropical jungle covered in snow", "src": "hdvideos/38.mp4"},
  {"caption": "Flying through an intense battle between pirate ships in a stormy ocean.", "src": "hdvideos/39.mp4"},
  {"caption": "Incredibly detailed science fiction scene set on an alien planet, view of a marketplace. Pixel art.", "src": "hdvideos/40.mp4"},
  {"caption": "Melting ice cream dripping down the cone.", "src": "hdvideos/41.mp4"},
  {"caption": "Melting pistachio ice cream dripping down the cone.", "src": "hdvideos/42.mp4"},
  {"caption": "Pouring latte art into a silver cup with a golden spoon next to it.", "src": "hdvideos/43.mp4"},
  {"caption": "Shoveling snow.", "src": "hdvideos/44.mp4"},
  {"caption": "Sprouts in the shape of text 'Imagen Video' coming out of a fairytale book.  Smooth animation.", "src": "hdvideos/45.mp4"},
  {"caption": "Sprouts in the shape of text 'Imagen Video' coming out of a fairytale book. Smooth video.", "src": "hdvideos/46.mp4"},
  {"caption": "Sprouts in the shape of text 'Imagen Video' coming out of a fairytale book.", "src": "hdvideos/47.mp4"},
  {"caption": "Studio shot of minimal kinetic sculpture made from thin wire shaped like a bird on white background.", "src": "hdvideos/49.mp4"},
  {"caption": "Thousands of fast brush strokes slowly forming the text 'Imagen Video' on a light beige canvas. Oil painting style. Smooth animation.", "src": "hdvideos/50.mp4"},
  {"caption": "Tiny plant sprout coming out of the ground.", "src": "hdvideos/51.mp4"},
  {"caption": "View of a castle with fantastically high towers reaching into the clouds in a hilly forest at dawn.", "src": "hdvideos/52.mp4"},
  {"caption": "Wooden figurine surfing on a surfboard in space.", "src": "hdvideos/53.mp4"},
  {"caption": "Wooden figurine walking on a treadmill made out of exercise mat.", "src": "hdvideos/54.mp4"},
  {"caption": "drone flythrough interior of sagrada familia cathedral", "src": "hdvideos/55.mp4"},
];

videos = hdvideos.sort((a, b) => 0.5 - Math.random());;

globalVideoIdx = 0;

function updateVideoSlot(idxVideo, idxSlot) {
  slot = $("#video_gallery > div").eq(idxSlot);

  src = videos[idxVideo].src;
  caption = videos[idxVideo].caption;

  slot.find("div.video_container > video > source").attr("src", src);
  slot.find("div.video_container > video")[0].load();
  slot.find("div.video_container > div.caption > div").text(caption);
}

function updateVideoGallery() {
  numVideos = videos.length;
  idxVideo = Math.floor(Math.random() * numVideos);

  numSlots = $("#video_gallery > div").length;
  idxSlot = Math.floor(Math.random() * numSlots);

  globalVideoIdx = ++globalVideoIdx % numVideos;
  updateVideoSlot(globalVideoIdx, idxSlot);

  setTimeout(updateVideoGallery, 6000);
}

function updateAllVideoSlots() {
  numVideos = videos.length;
  numSlots = $("#video_gallery > div").length;

  globalVideoIdx = Math.floor(Math.random() * numVideos);
  for (var i = 0; i < numSlots; ++i, ++globalVideoIdx) {
    globalVideoIdx = globalVideoIdx % numVideos;
    updateVideoSlot(globalVideoIdx, i);
  }
}

function addVideoSlot(idx) {
  if (idx < 8) {
    template = `
  <div class="video_wrapper">
    <div class="video_container">
      <video autoplay loop muted playsinline><source src="videos/fairytale.mp4" type="video/mp4"></video>
      <div class="caption">
        <div></div>
      </div>
    </div>
  </div>
  `;
  } else {
    template = `
  <div class="video_wrapper nomobile">
    <div class="video_container">
      <video autoplay loop muted playsinline><source src="videos/fairytale.mp4" type="video/mp4"></video>
      <div class="caption">
        <div></div>
      </div>
    </div>
  </div>
  `;
  }

  $("#video_gallery").append(template);
}

function playVideo(id, src) {
  $(id + " video > source").attr("src", src);
  $(id + " video")[0].load();
}

// playVideo("#header_video", "videos/fairytale.mp4");

for (var i = 0; i < 16; ++i) {
  addVideoSlot(i);
}

updateAllVideoSlots();
setTimeout(updateVideoGallery, 6000);

// drawT5();

$(window).scroll(function() {
  $("#title").each(title);
  zoom();
  cdm();
  unet();
});
    </script>
  </body>
</html>
